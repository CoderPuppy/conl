local pl = require 'pl.import_into' ()

def lex = module({
	export def t = struct([
		file: lua.any,
		rules: lex.rules,
		tokens: list(lua.any),
		next-token: int,
		buffer: string,
		buffer-pos: int,
		linear-pos: int,
	])

	export def init = { (file, rules) in t.make([
		file: file,
		rules: rules,
		tokens: [],
		next-token: 1,
		buffer: '',
		buffer-pos: 1,
		linear-pos: 1,
	]) }

	export def t.instance.buffer-remaining = { (self) in #self.buffer - self.buffer-pos + 1 }

	export def t.instance.read = { (self, n) in
		while self.buffer-remaining() < n {
			let new = self.file.read(:, 1024 * 1024)
			if new == nil { break }
			if self.buffer-pos > 1 {
				self.buffer = self.buffer.sub(:, self.buffer-pos)
				self.buffer-pos = 1
			}
			self.buffer ..= new
		}
	}

	export def t.instance.match = { (self, pat) in
		if let *match = self.buffer.match(:, '^(' .. pat .. ')', self.buffer-pos) {
			self.buffer-pos += #match[1]
			self.linear-pos += #match[1]
			return *match
		} else {
			return nil
		}
	}

	export def t.instance.peek = { (self) in
		while #self.tokens < self.next-token {
			self.read(rules.lookahead)
			if self.buffer-remaining() == 0 { return nil }
			for rule in self.rules {
				let start-pos = self.linear-pos
				if let *match = self.match(rule.pat) {
					if let mut ext-pat = rule.ext-pat {
						if ext-pat == true {
							ext-pat = rule.pat
						}
						while self.buffer-pos == #self.buffer + 1 {
							self.read(self.rules.lookahead)
							if let *ext-match = self.match(ext-pat) {
								match[++] = ext-match
							} else {
								break
							}
						}
					}
					rule.act(self, start-pos, *match)
					break
				}
			} else {
				error(('no rule matched: %q').format(:, self.buffer.sub(:, self.buffer-pos)))
			}
		}
		return self.tokens[self.next-token]
	}

	export def t.instance.pull = { (self) in
		let token = self.peek()
		self.tokens[self.next-token] = nil
		if self.next-token == #self.tokens {
			#self.tokens = 0
			self.next-token = 1
		} else {
			self.next-token += 1
		}
		return token
	}

	export def t.instance.switch-rules = { (self, new-rules) in
		assert(#self.tokens == 0)
		self.rules = new-rules
	}

	export def t.instance.save = { (self) in
		let save = [
			pos: self.file.seek(:) - #self.buffer + self.buffer-pos - 1;
			rules: self.rules,
			tokens: [],
			linear-pos: self.linear-pos,
		]
		for i in range(self.next-token, #self.tokens) {
			save.tokens[++] = self.tokens[i]
		}
		return save
	}

	export def t.instance.restore = { (self, save) in
		self.file.seek(:, 'set', save.pos)
		self.rules = save.rules
		self.tokens = [*save.tokens]
		self.next-token = 1
		self.buffer = ''
		self.buffer-pos = 1
		self.linear-pos = save.linear-pos
	}

	export def act-token = { (typ) in { (self, start-pos, text, *captures) in
		self.tokens[++] = [
			type: typ,
			text: text,
			start-pos: start-pos,
			captures: captures,
		]
	} }

	export def act-block = { (typ) in { (self, start-pos, mut full-text) in
		let mut n = 0
		while let text = (self.read(1); self.match('%=+')) {
			n += #text
			full-text ..= text
		}
		if let text = (self.read(1); self.match('%[')) {
			full-text ..= text
		} else {
			error(('TODO: %q').format(:, self.buffer.sub(:, self.buffer-pos)))
		}
		let mut contents = ''
		while true {
			if let text = (self.read(n + 2); self.match('%]' .. ('=').rep(:, n) .. '%]')) {
				full-text ..= text
				break
			}
			if let text = (self.read(2); self.match('%]?[^%]]*')) {
				if text == '' {
					error('TODO')
				}
				full-text ..= text
				contents ..= text
			}
		}
		self.tokens[++] = [
			type: typ,
			text: full-text,
			start-pos: start-pos,
			captures: [contents],
		]
	} }

	export def make-rules = { (rules) in
		-- TODO
		-- if not rules.n then
		-- 	rules.n = #rules
		-- end
		-- local n = 1
		-- for i = 1, rules.n do
		-- 	if rules[i].n > n then
		-- 		n = rules[i].n
		-- 	end
		-- end
		-- rules.lookahead = n
		-- return rules
	}

	export def rules-t = TODO

	export def rules = make-rules([
		[n:1, pat:'\'', act:act-token('quote')],
		[n:1, pat:'"', act:act-token('quote')],
		[n:1, pat:'%(', act:act-token('open_paren')],
		[n:1, pat:'%)', act:act-token('close_paren')],
		[n:1, pat:'{', act:act-token('open_brace')],
		[n:1, pat:'}', act:act-token('close_brace')],
		[n:1, pat:'%[', act:act-token('open_bracket')],
		[n:1, pat:'%]', act:act-token('close_bracket')],
		[n:1, pat:',', act:act-token('comma')],
		[n:1, pat:'%.', act:act-token('dot')],
		[n:3, pat:'%-%-%[', ext_pat:'[^\r\n]+', act:act-block('block_comment')],
		[n:2, pat:'%-%-([^\r\n]*)', ext_pat:'([^\r\n]+)', act:act-token('line_comment')],
		[n:2, pat:'\r?\n', act:act-token('newline')],
		[n:1, pat:'[^%S\n]+', ext_pat:true, act:act-token('linear_ws')],
		[n:1, pat:'[^()%[%]{}%s\'",%.]+', ext_pat:true, act:act-token('identifier')],
	])
	export def rules-string = make-rules([
		[n:1, pat:'\'', act:act-token('quote')],
		[n:1, pat:'"', act:act-token('quote')],
		[n:2, pat:'\\[nrte\'"\\]', act:act-token('escape')],
		[n:1, pat:'[^\\\'"]+', ext_pat:true, act:act-token('text')],
	])
})

def lex-indent = module({
	export def t = struct([
		lex: lex.t,
		indent: maybe(list(string)),
		pending: maybe(lua.any),
	])

	export def init = { (lex) in t.make([
		lex: lex,
		indent: nil,
		pending: nil,
	]) }

	export def t.instance.peek = { (self) in
		if let p = self.pending {
			return p
		} else {
			let mut token = self.lex.peek()
			if self.indent == nil {
				let mut indent = ''
				while token.type == 'linear_ws' {
					indent ..= token.text
					self.lex.pull()
					token = self.lex.peek()
				}
				self.indent = [indent]
			}
			return token
		}
	}

	export def t.instance.pull = { (self) in
		let token = self.peek()
		if self.pending {
			self.pending = nil
		} else {
			self.lex.pull()
			if token && token.type == 'newline' {
				let mut new-indent = ''
				let eof = !self.lex.peek()
				let mut next-token
				while true {
					next-token = self.lex.peek()
					if !next-token || next-token.type != 'linear_ws' {
						break
					}
					self.lex.pull()
					new-indent ..= next-token.text
				}
				if next-token && next-token.type != 'newline' {
					let cur-indent = self.indent[#self.indent]
					if new-indent == cur-indent {
					} else if new-indent.sub(1, #cur-indent) == cur-indent {
						self.indent[++] = new-indent
						self.pending = [ type: 'indent', relative: new-indent.sub(#cur-indent + 1) ]
					} else if cur-indent.sub(1, #new-indent) == new-indent {
						if #self.indent == 1 && !eof {
							-- the `not eof` is to accept a trailing newline (unix style), which would not have any indentation after it
							error(('dedent below initial level: old = %q, new = %q').format(cur-indent, new-indent))
						}
						self.indent[#self.indent] = nil
						self.pending = [ type: 'dedent', relative: cur-indent.sub(#new.indent + 1) ]
					} else {
						error(('bad indentation: old = %q, new = %q').format(cur-indent, new-indent))
					}
				}
			}
		}
	}

	export def t.instance.save = { (self) in
		let save = [
			lex: self.lex.save(),
			pending: self.pending,
			indent: [*self.indent],
		]
		return save
	}

	export def t.instance.restore = { (self, save) in
		self.lex.restore(save.lex)
		self.pending = save.pending
		self.indent = [*save.indent]
	}
})

local h = io.open('test.conl', 'r')
local lex_state = lex_init(h, lex_rules)
local lex_indent_state = lex_indent_init(lex_state)
local function is_ws(token)
	if not token then
		return false
	end
	return false
		or token.type == 'linear_ws'
		or token.type == 'newline'
		or token.type == 'line_comment'
		or token.type == 'block_comment'
		or token.type == 'indent'
		or token.type == 'dedent'
end
local function skip_ws()
	while true do
		local token = lex_indent_peek(lex_indent_state)
		if is_ws(token) then
			lex_indent_pull(lex_indent_state)
		else
			break
		end
	end
end
local parse_expr
local function parse_expr_atom()
	local token = lex_indent_peek(lex_indent_state)
	if not token then
		return nil
	elseif token.type == 'identifier' then
		lex_indent_pull(lex_indent_state)
		if token.text == 'let' then
			local name
			while true do
				local token = lex_indent_pull(lex_indent_state)
				if token.type == 'identifier' then
					name = token.text
					break
				elseif token.type == 'linear_ws' then
				else
					error(('TODO: token.type = %q'):format(token.type))
				end
			end
			skip_ws()
			while true do
				local token = lex_indent_pull(lex_indent_state)
				if token.type == 'identifier' and token.text == '=' then
					break
					error(('TODO: token.type = %q'):format(token.type))
				end
			end
			skip_ws()
			local val = assert(parse_expr(0))
			return {
				type = 'let';
				name = name;
				val = val;
			}
		elseif token.text == 'const' then
			skip_ws()
			local token = lex_indent_pull(lex_indent_state)
			assert(token.type == 'identifier')
			local name = token.text
			skip_ws()
			local token = lex_indent_pull(lex_indent_state)
			assert(token.type == 'identifier' and token.text == '=')
			skip_ws()
			local val = assert(parse_expr(0))
			return {
				type = 'const';
				name = name;
				val = val;
			}
		else
			return {
				type = 'var';
				name = token.text;
			}
		end
	elseif token.type == 'quote' then
		lex_indent_pull(lex_indent_state)
		local quote = token.text
		lex_switch_rules(lex_state, lex_rules_string)
		local text = ''
		while true do
			token = lex_pull(lex_state)
			if token.type == 'text' then
				text = text .. token.text
			elseif token.type == 'quote' then
				if token.text == quote then
					break
				else
					text = text .. token.text
				end
			else
				error(('TODO: token.type = %q'):format(token.type))
			end
		end
		lex_switch_rules(lex_state, lex_rules)
		return {
			type = 'str';
			text = text;
		}
	elseif token.type == 'open_brace' then
		lex_indent_pull(lex_indent_state)
		skip_ws()
		local save = lex_indent_save(lex_indent_state)
		local ok, args = pcall(function()
			local args = {n = 0;}
			local token = lex_indent_pull(lex_indent_state)
			assert(token.type == 'open_paren')
			while true do
				local token = lex_indent_pull(lex_indent_state)
				if is_ws(token) then
				elseif token.type == 'identifier' then
					args.n = args.n + 1
					args[args.n] = token.text
					skip_ws()
					local token = lex_indent_pull(lex_indent_state)
					if token.type == 'comma' then
					elseif token.type == 'close_paren' then
						goto args_list_done
					else
						error(('TODO: token.type = %q'):format(token.type))
					end
				elseif token.type == 'close_paren' then
					goto args_list_done
				else
					error(('TODO: token.type = %q'):format(token.type))
				end
			end
			::args_list_done::
			skip_ws()
			token = lex_indent_pull(lex_indent_state)
			assert(token.type == 'identifier' and token.text == 'in')
			return args
		end)
		if ok then
		else
			print(args, debug.traceback())
			args = nil
			lex_indent_restore(lex_indent_state, save)
		end
		local body = {n = 0;}
		while true do
			skip_ws()
			local token = lex_indent_peek(lex_indent_state)
			if token.type == 'close_brace' then
				lex_indent_pull(lex_indent_state)
				goto done
			end
			body.n = body.n + 1
			body[body.n] = assert(parse_expr(0))
		end
		::done::
		return {
			type = 'fn';
			args = args;
			body = body;
		}
	elseif token.type == 'open_paren' then
		lex_indent_pull(lex_indent_state)
		local body = {n = 0;}
		while true do
			skip_ws()
			local token = lex_indent_peek(lex_indent_state)
			if token.type == 'close_paren' then
				lex_indent_pull(lex_indent_state)
				goto done
			end
			body.n = body.n + 1
			body[body.n] = assert(parse_expr(0))
		end
		::done::
		return {
			type = 'block';
			body = body;
		}
	else
		-- error(('TODO: token.type = %q'):format(token.type))
		return nil
	end
end
local function parse_postop(prec)
	local token = lex_indent_peek(lex_indent_state)
	if not token then
		return nil
	elseif token.type == 'open_paren' then
		lex_indent_pull(lex_indent_state)
		local args = {n = 0;}
		while true do
			skip_ws()
			local token = lex_indent_peek(lex_indent_state)
			if token.type == 'close_paren' then
				lex_indent_pull(lex_indent_state)
				goto args_done
			end
			args.n = args.n + 1
			args[args.n] = assert(parse_expr(0))
			token = lex_indent_pull(lex_indent_state)
			if token.type == 'close_paren' then
				goto args_done
			elseif token.type == 'comma' then
				break
			else
				error(('TODO: token.type = %q'):format(token.type))
			end
		end
		::args_done::
		return function(head) return {
			type = 'call';
			fn = head;
			args = args;
		} end
	elseif token.type == 'open_bracket' then
		lex_indent_pull(lex_indent_state)
		local args = {n = 0;}
		while true do
			skip_ws()
			local token = lex_indent_peek(lex_indent_state)
			if token.type == 'close_paren' then
				lex_indent_pull(lex_indent_state)
				goto args_done
			end
			args.n = args.n + 1
			args[args.n] = assert(parse_expr(0))
			token = lex_indent_pull(lex_indent_state)
			if token.type == 'close_bracket' then
				goto args_done
			elseif token.type == 'comma' then
			else
				error(('TODO: token.type = %q'):format(token.type))
			end
		end
		::args_done::
		return function(head) return {
			type = 'index';
			fn = head;
			args = args;
		} end
	elseif token.type == 'identifier' then
		if token.text == '+' then
			lex_indent_pull(lex_indent_state)
			skip_ws()
			local right = assert(parse_expr(0))
			return function(head) return {
				type = 'binop';
				op = '+';
				left = head;
				right = right;
			} end
		elseif token.text == '=' then
			lex_indent_pull(lex_indent_state)
			skip_ws()
			local val = assert(parse_expr(0))
			return function(head) return {
				type = 'assign';
				to = head;
				val = val;
			} end
		else
			return nil
		end
	elseif token.type == 'dot' then
		lex_indent_pull(lex_indent_state)
		local name
		while true do
			local token = lex_indent_pull(lex_indent_state)
			if token.type == 'identifier' then
				name = token.text
				break
			else
				error(('TODO: token.type = %q'):format(token.type))
			end
		end
		return function(head) return {
			type = 'access';
			head = head;
			name = name;
		} end
	else
		return nil
	end
end
function parse_expr(prec)
	local expr = parse_expr_atom()
	if not expr then
		return nil
	end
	while true do
		skip_ws()
		local op = parse_postop(prec)
		if op then
			expr = op(expr)
		else
			break
		end
	end
	return expr
end
local body = {n = 0;}
while true do
	local expr = parse_expr(0)
	if expr then
		body.n = body.n + 1
		body[body.n] = expr
	else
		break
	end
end
assert(lex_indent_peek(lex_indent_state) == nil)
print(pl.pretty.write(body))
